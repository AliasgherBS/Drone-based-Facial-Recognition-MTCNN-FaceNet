{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b34d08",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044ac9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow\n",
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "#Augmentation\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a1c10",
   "metadata": {},
   "source": [
    "# Alignment Class [MTCNN backed]\n",
    "\n",
    "The code below will input the image. Then it detects the face or faces in the image. It then selects the largest face (most pixels in it) and detects the centers of the left and right eye. It then determines the angle of the line joining the eye centers. This angle is then feed into a function that rotates the image so the line is paralllel to the x axis. Then the rotatedimage is cropped to return the largest face and the image is stored in the working/dir/car. MTCNN is the most acurate face cropper I have found but unfortunately it is very slow. \n",
    "\n",
    "First allignment of the dataset is done using MTCNN model, alignment basically means to detect a face and then using trignometric functions and landmarks of the face, the face is rotated in a way that eyes are aligned horizaontally, all of this done to make all the images have same orientation and alignment helps achieve better accuracy also.\n",
    "\n",
    "The width and height are optional arguments that can be used to resize all the processed image into a fixed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f16d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAligner:\n",
    "    def __init__(self, detector):\n",
    "        self.detector = detector\n",
    "    \n",
    "    def align(self, img):\n",
    "        data = self.detector.detect_faces(img)  # Use the detector to detect the faces in the image\n",
    "        biggest = 0\n",
    "        if data != []:  # If at least one face is detected\n",
    "            for faces in data:\n",
    "                box = faces['box']  # Get the bounding box coordinates of the face\n",
    "                area = box[3] * box[2]  # Calculate the area of the bounding box\n",
    "                if area > biggest:  # If this is the largest face so far, update the biggest area\n",
    "                    biggest = area\n",
    "                    bbox = box\n",
    "                    keypoints = faces['keypoints']  # Get the keypoints of the face\n",
    "                    left_eye = keypoints['left_eye']  # Get the coordinates of the left eye\n",
    "                    right_eye = keypoints['right_eye']  # Get the coordinates of the right eye\n",
    "            lx, ly = left_eye  # Unpack the coordinates of the left eye\n",
    "            rx, ry = right_eye  # Unpack the coordinates of the right eye\n",
    "            dx = rx - lx  # Calculate the difference in x-coordinates between the eyes\n",
    "            dy = ry - ly  # Calculate the difference in y-coordinates between the eyes\n",
    "            tan = dy / dx  # Calculate the tangent of the angle between the eyes\n",
    "            theta = np.arctan(tan)  # Calculate the angle in radians\n",
    "            theta = np.degrees(theta)  # Convert the angle to degrees\n",
    "            img = self.rotate_bound(img, theta)  # Rotate the image by the calculated angle\n",
    "            return (True, img)  # Return a tuple indicating success and the rotated image\n",
    "        else:  # If no face is detected\n",
    "            return (False, img)  # Return a tuple indicating failure and no image\n",
    "\n",
    "\n",
    "    def crop_image(self, img):\n",
    "        data = self.detector.detect_faces(img)\n",
    "        biggest = 0\n",
    "        if data != []:\n",
    "            for faces in data:\n",
    "                box = faces['box']\n",
    "                area = box[3] * box[2]\n",
    "                if area > biggest:\n",
    "                    biggest = area\n",
    "                    bbox = box\n",
    "            bbox[0] = 0 if bbox[0] < 0 else bbox[0]\n",
    "            bbox[1] = 0 if bbox[1] < 0 else bbox[1]\n",
    "            img = img[bbox[1]: bbox[1] + bbox[3], bbox[0]: bbox[0] + bbox[2]]\n",
    "            return (True, img)\n",
    "        else:\n",
    "            return (False, img)\n",
    "\n",
    "    def rotate_bound(self, image, angle):\n",
    "        (h, w) = image.shape[:2]\n",
    "        (cX, cY) = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "        nW = int((h * sin) + (w * cos))\n",
    "        nH = int((h * cos) + (w * sin))\n",
    "        M[0, 2] += (nW / 2) - cX\n",
    "        M[1, 2] += (nH / 2) - cY\n",
    "        return cv2.warpAffine(image, M, (nW, nH))\n",
    "    \n",
    "    def align_db(self, main_folder, aligned_folder ,height=None, width=None):\n",
    "        \n",
    "        for subfolder in os.listdir(main_folder):\n",
    "            subfolder_path = os.path.join(main_folder, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                \n",
    "                aligned_subfolder_path = os.path.join(aligned_folder, subfolder)\n",
    "                if not os.path.exists(aligned_subfolder_path):\n",
    "                    os.mkdir(aligned_subfolder_path)\n",
    "                \n",
    "                for image_name in os.listdir(subfolder_path):\n",
    "                    image_path = os.path.join(subfolder_path, image_name)\n",
    "\n",
    "                    aligned_image_path = os.path.join(aligned_subfolder_path, image_name)\n",
    "\n",
    "                    img = cv2.imread(image_path)\n",
    "                    success, img = self.align(img)\n",
    "                    if success:\n",
    "                        successT, img = self.crop_image(img)\n",
    "                        if successT:\n",
    "                            if height is not None and width is not None:\n",
    "                                img = cv2.resize(img, (width, height))\n",
    "                    cv2.imwrite(aligned_image_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820c9a4",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664e72c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "9/9 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "11/11 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "7/7 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set the path to database folder containing the images\n",
    "db_folder = '../Databases/Original/ibad'\n",
    "\n",
    "aligned_folder = '../Databases/Alligned/ibad'\n",
    "\n",
    "if not os.path.exists(aligned_folder):\n",
    "    os.makedirs(aligned_folder)\n",
    "\n",
    "# Load the MTCNN model\n",
    "detector = MTCNN()\n",
    "\n",
    "\n",
    "image_aligner = ImageAligner(detector)\n",
    "image_aligner.align_db(db_folder, aligned_folder, height=160, width=160)\n",
    "# image_aligner.align_db(db_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3f923",
   "metadata": {},
   "source": [
    "# Augmentation [imgaug backed]\n",
    "\n",
    "The code defines a set of image augmentations that can be applied to images as a form of data augmentation. The augmentations are defined using the imgaug library, which is a library for image augmentation in Python.\n",
    "\n",
    "The specific augmentations defined in the code are:\n",
    "\n",
    "Affine rotation: rotates the image by a random angle between -20 and 20 degrees.\n",
    "Brightness adjustment: multiplies the brightness of the image by a random factor between 0.5 and 1.5 and adds a random value between -30 and 30 to the brightness.\n",
    "Gaussian blur: adds a Gaussian blur with a random sigma value between 0 and 1.5.\n",
    "Additive Gaussian noise: adds Gaussian noise with a standard deviation up to 5% of the image intensity range.\n",
    "Affine scaling: scales the image along the x and y axes by a random factor between 0.8 and 1.2.\n",
    "\n",
    "These augmentations can be applied to input images to create additional training examples for machine learning models, which can improve the performance and robustness of the models. By applying these augmentations, the model can learn to recognize faces that have been rotated, scaled, or have different levels of brightness or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a09a4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the augmentations\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-20, 20)), # rotate between -20 and 20 degrees\n",
    "    iaa.MultiplyAndAddToBrightness(mul=(0.5, 1.5), add=(-30, 30)), # adjust brightness by up to +/-30\n",
    "    iaa.GaussianBlur(sigma=(0, 1.5)), # add Gaussian blur with sigma between 0 and 1.5\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)), # add Gaussian noise with standard deviation up to 5% of image intensity range\n",
    "    iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}), # scale image by up to 20%\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807eda6",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the main folder\n",
    "main_folder = \"../Misc/DroneFace/Height_Distance/database_n\"\n",
    "\n",
    "# Loop over every subfolder in the main folder\n",
    "for folder in os.listdir(main_folder):\n",
    "    folder_path = os.path.join(main_folder, folder)\n",
    "    \n",
    "    # Only process the subfolders that contain images\n",
    "    if os.path.isdir(folder_path) and any(filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")) for filename in os.listdir(folder_path)):\n",
    "\n",
    "        # Loop over every image in the subfolder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "                \n",
    "                # read image from file\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Convert the image to a numpy array\n",
    "                img_arr = np.array(image)\n",
    "\n",
    "                # Augment the image 20 times\n",
    "                images_aug = seq(images=np.tile(img_arr, (20, 1, 1, 1)))\n",
    "\n",
    "                # Save the augmented images using OpenCV\n",
    "                for i in range(20):\n",
    "                    # Save the image\n",
    "                    cv2.imwrite(image_path + f'augmented_{i}.jpg', images_aug[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
